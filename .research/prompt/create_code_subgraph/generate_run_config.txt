
LLM Name: o3-2025-04-16
Input:
You are an AI research assistant tasked with generating Hydra configuration files for experiment runs.

# Task
Generate individual YAML configuration files for each experiment run. These configs will be used by Hydra to configure specific experimental variations.

# Input Information

## Research Method
{
    "Open Problems": "1. BOIL estimates the wall-clock cost of evaluating a hyper-parameter setting with a plain LinearRegression model.  In practice the relation (e.g. GPU time, number of simulator steps) is highly non-linear and heteroscedastic.\n2. The acquisition function divides the expected utility by the point estimate of the cost, ignoring its uncertainty; when the cost model is wrong the optimiser can select apparently cheap but actually expensive configurations, wasting budget.\n3. Both shortcomings can be fixed with a very small change – replacing the linear cost surrogate with a probabilistic model and letting the acquisition treat cost uncertainty explicitly.",
    "Methods": "Method name: CA-BOIL (Cost-Aware BOIL)\nMinimal changes to BOIL:\n1. Replace the LinearRegression cost model with a second Gaussian-Process surrogate GP_c(x,t) that yields mean µ_c and standard deviation σ_c of the (log) cost.\n2. Redefine the acquisition used in utility_cost_evaluation from\n        U_old =  log(EI) – log(µ_c)\n   to the cost-uncertainty–aware\n        U_new =  EI /( µ_c + κ · σ_c )\n   (equivalently  log(EI) – log(µ_c+κσ_c) in BOIL’s code).  κ≥0 is a single scalar (default κ=1).\nTheoretical intuition:\n• GP_c gives a calibrated posterior over cost.  Dividing by µ_c+κσ_c is the familiar concept of \"expected improvement per (risk-adjusted) cost\"; high uncertainty on cost is penalised so the optimiser prefers configurations that are both promising and reliably cheap.\n• The change keeps BOIL’s product-kernel GP for utility, the learning-curve compression, the data-augmentation, etc. completely intact – only 25 lines of code are touched.",
    "Experimental Setup": "Goal: show that CA-BOIL reaches the same test accuracy with less wall-clock time than vanilla BOIL.\nTask: tune (learning-rate, hidden-units) of an MLP on the Fashion-MNIST dataset for 10 epochs.\nTrue cost: measured GPU time per evaluation (simulated here as  0.4·hidden_units + 1200·learning_rate^2  + noise).\nProtocol:\n1. Use the public BOIL implementation as the baseline (n_init_points=3, budget 40 evaluations).\n2. Implement CA-BOIL by adding GP_c and U_new (κ=1).\n3. Run each optimiser 20 times with different random seeds.\nMetrics:\n• Best validation accuracy reached vs. cumulative true time (area under curve).\n• Total time to reach 85% accuracy.",
    "Experimental Code": "import numpy as np, time, torch, sklearn\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern, WhiteKernel\n\n# === tiny wrapper around the user objective =================================\n\ndef objective(cfg):\n    lr, h = cfg  # learning-rate, hidden units\n    start = time.time()\n    # --- train a very small network for 10 epochs (placeholder) ------------\n    acc = 1.0 - (lr*3 + (200-h)/400) + np.random.randn()*0.01  # fake accuracy\n    true_cost = 0.4*h + 1200*lr**2 + np.random.rand()*3        # fake time\n    return acc, np.log(true_cost), time.time()-start\n\n# === cost-aware acquisition =================================================\n\ndef expected_improvement(mu, sigma, y_best):\n    from scipy.stats import norm\n    z = (mu - y_best)/sigma\n    return (mu - y_best)*norm.cdf(z) + sigma*norm.pdf(z)\n\ndef acquisition(X, gp_u, gp_c, y_best, kappa):\n    mu_u, sigma_u = gp_u.predict(X, return_std=True)\n    mu_c, sigma_c = gp_c.predict(X, return_std=True)\n    ei = expected_improvement(mu_u, sigma_u, y_best)\n    return ei / (mu_c + kappa*sigma_c)\n\n# === minimal CA-BOIL optimisation loop (no virtual obs for brevity) =========\n\nbounds = np.array([[1e-4, 1e-1],   # learning rate\n                   [ 50 , 400 ]])  # hidden units\n\ngp_u = GaussianProcessRegressor(Matern()+WhiteKernel(1e-5))\ngp_c = GaussianProcessRegressor(Matern()+WhiteKernel(1e-5))\n\nX, y_u, y_c = [], [], []\n# initial design\nfor _ in range(3):\n    x = np.random.uniform(bounds[:,0], bounds[:,1])\n    acc, cost_log, _ = objective(x)\n    X.append(x)\n    y_u.append(acc)\n    y_c.append(cost_log)\n\nfor it in range(37):  # total 40\n    gp_u.fit(np.array(X), np.array(y_u))\n    gp_c.fit(np.array(X), np.array(y_c))\n\n    y_best = np.max(y_u)\n    # optimise acquisition by random search (sufficient for demo)\n    cand = np.random.uniform(bounds[:,0], bounds[:,1], size=(5000,2))\n    acq_values = acquisition(cand, gp_u, gp_c, y_best, kappa=1.0)\n    x_next = cand[np.argmax(acq_values)]\n\n    acc, cost_log, _ = objective(x_next)\n    X.append(x_next)\n    y_u.append(acc)\n    y_c.append(cost_log)\n\nprint('best val acc', np.max(y_u))\n",
    "Expected Result": "Across 20 independent runs CA-BOIL reduces the median wall-clock time to reach 85% accuracy by ≈20-30% compared with BOIL, and achieves slightly higher final accuracy for the same fixed time budget because it avoids a few very costly evaluations that BOIL selects due to under-estimated cost.",
    "Expected Conclusion": "By swapping the linear cost surrogate for a simple GP and dividing the improvement by a risk-adjusted cost estimate, CA-BOIL becomes less prone to costly mistakes while keeping BOIL’s strengths (learning-curve compression and data augmentation).  The single added κ hyper-parameter and ~25 lines of code yield a consistent speed-up, demonstrating that even very small, principled modifications can translate into tangible efficiency gains in hyper-parameter optimisation."
}

## Experimental Design
{'experiment_summary': 'We benchmark the new Cost-Aware BOIL (CA-BOIL) hyper-parameter optimiser against the original BOIL on a medium-size neural-network tuning task.  The optimiser must find the learning-rate (10⁻⁴–10⁻¹) and hidden-layer width (50–400 units) that maximise validation accuracy of a 2-layer MLP after ten training epochs on Fashion-MNIST while paying the true wall-clock cost of each trial (measured GPU time).  \nWorkflow\n1. Dataset loading: Fashion-MNIST train/validation split.\n2. Model definition: a fixed 2-layer MLP (≈0.1 M parameters) implemented in PyTorch.\n3. Objective function: (cfg) ↦ (validation-accuracy, log(cost)).  Cost is obtained through torch.cuda.Event timers.\n4. Optimisers:\n   • BOIL baseline: single GP for utility, linear regression for cost, acquisition U_old = log(EI) – log(µ_c).\n   • Proposed CA-BOIL: identical utility GP but replaces the linear cost model with a GP GP_c and uses acquisition U_new = EI / (µ_c + κ σ_c) (κ = 1).\n5. Loop: 3 Sobol initial points + 37 adaptive steps (budget 40).  Both methods are repeated for 20 random seeds on the same machine (8 × A100, 80 GB each).\n6. Logging: after every evaluation we record cumulative wall-clock time, best validation accuracy, chosen hyper-parameters, and acquisition value.\n7. Post-processing: compute per-run curves best-acc(t), integrate AUC, and measure the time when 85 % validation accuracy is first reached.\n8. Statistical analysis: report median and 95 %-CI across seeds, and perform two-sided Wilcoxon signed-rank tests on each metric.\nThe experiment demonstrates that CA-BOIL reaches 85 % accuracy ≈25 % faster and avoids extreme outliers in time consumption, validating that modelling cost uncertainty yields more budget-robust optimisation.', 'evaluation_metrics': ['Area Under Best-Accuracy–Time Curve', 'Time To 85% Accuracy', 'Final Best Validation Accuracy'], 'proposed_method': 'Cost-Aware BOIL (CA-BOIL)\nObjective: accelerate Bayesian Optimisation with Inequality Learning (BOIL) by taking uncertainty in evaluation cost into account.\nKey ideas:\n1. Probabilistic cost surrogate: replace BOIL’s linear regression on observed (log) costs with a Gaussian-Process surrogate GP_c(x,t) with Matern + white kernels.  The GP yields a posterior mean µ_c(x) and standard deviation σ_c(x).\n2. Risk-adjusted acquisition: for a candidate configuration x the utility acquisition is defined as\n      U_new(x) = EI(x) / ( µ_c(x) + κ σ_c(x) ),\n   where EI is the standard Expected Improvement of the utility GP and κ≥0 (default 1) controls cost-risk aversion.\n3. Implementation: only ~25 lines change in the open-source BOIL codebase—add a second GP object, train it on the same design points’ logged costs, and swap one line in utility_cost_evaluation to compute U_new.\n4. Algorithmic steps per BO iteration:\n   a. Fit GP_u on (x, validation_accuracy).\n   b. Fit GP_c on (x, log(cost)).\n   c. Maximise U_new(x) over the search space via Thompson sampling + local L-BFGS.\n   d. Evaluate the objective at x*, append the new data, repeat until budget.\nTheoretically, dividing EI by a risk-adjusted denominator is equivalent to optimising expected improvement per unit of cost under a mean-variance formulation, so candidates with high cost uncertainty are automatically down-weighted.  The method preserves every other aspect of BOIL (learning-curve compression, virtual observations, product kernels) and introduces only one additional scalar hyper-parameter κ.', 'comparative_methods': ['Vanilla BOIL (Linear-Cost Surrogate)'], 'models_to_use': ['2-Layer MLP (≈0.1M parameters)'], 'datasets_to_use': ['Fashion-MNIST'], 'hyperparameters_to_search': {'learning_rate': '1e-4-1e-1', 'hidden_units': '50-400', 'kappa': '0.5-2.0'}, 'external_resources': {'hugging_face': {'models': [], 'datasets': [{'id': 'zalando-datasets/fashion_mnist', 'author': 'zalando-datasets', 'sha': '531be5e2ccc9dba0c201ad3ae567a4f3d16ecdd2', 'created_at': datetime.datetime(2022, 3, 2, 23, 29, 22, tzinfo=TzInfo(UTC)), 'last_modified': datetime.datetime(2024, 8, 8, 6, 10, 25, tzinfo=TzInfo(UTC)), 'private': False, 'gated': False, 'disabled': False, 'downloads': 10367, 'likes': 63, 'siblings': [{'rfilename': '.gitattributes', 'size': None, 'blob_id': None, 'lfs': None}, {'rfilename': 'README.md', 'size': None, 'blob_id': None, 'lfs': None}, {'rfilename': 'fashion_mnist/test-00000-of-00001.parquet', 'size': None, 'blob_id': None, 'lfs': None}, {'rfilename': 'fashion_mnist/train-00000-of-00001.parquet', 'size': None, 'blob_id': None, 'lfs': None}], 'card_data': {'license': ['mit'], 'language': ['en'], 'library_name': None, 'pipeline_tag': None, 'tags': [], 'datasets': [], 'model_type': None, 'base_model': None, 'task_categories': ['image-classification'], 'size_categories': ['10K<n<100K'], 'metrics': [], 'widget': []}, 'tags': ['task_categories:image-classification', 'task_ids:multi-class-image-classification', 'annotations_creators:expert-generated', 'language_creators:found', 'multilinguality:monolingual', 'source_datasets:original', 'language:en', 'license:mit', 'size_categories:10K<n<100K', 'format:parquet', 'modality:image', 'library:datasets', 'library:pandas', 'library:mlcroissant', 'library:polars', 'arxiv:1708.07747', 'region:us'], 'pipeline_tag': None, 'library_name': None, 'readme': '---\nannotations_creators:\n- expert-generated\nlanguage_creators:\n- found\nlanguage:\n- en\nlicense:\n- mit\nmultilinguality:\n- monolingual\nsize_categories:\n- 10K<n<100K\nsource_datasets:\n- original\ntask_categories:\n- image-classification\ntask_ids:\n- multi-class-image-classification\npaperswithcode_id: fashion-mnist\npretty_name: FashionMNIST\ndataset_info:\n  config_name: fashion_mnist\n  features:\n  - name: image\n    dtype: image\n  - name: label\n    dtype:\n      class_label:\n        names:\n          \'0\': T - shirt / top\n          \'1\': Trouser\n          \'2\': Pullover\n          \'3\': Dress\n          \'4\': Coat\n          \'5\': Sandal\n          \'6\': Shirt\n          \'7\': Sneaker\n          \'8\': Bag\n          \'9\': Ankle boot\n  splits:\n  - name: train\n    num_bytes: 31049107.0\n    num_examples: 60000\n  - name: test\n    num_bytes: 5192560.0\n    num_examples: 10000\n  download_size: 36106894\n  dataset_size: 36241667.0\nconfigs:\n- config_name: fashion_mnist\n  data_files:\n  - split: train\n    path: fashion_mnist/train-*\n  - split: test\n    path: fashion_mnist/test-*\n  default: true\n---\n\n# Dataset Card for FashionMNIST\n\n## Table of Contents\n- [Dataset Description](#dataset-description)\n  - [Dataset Summary](#dataset-summary)\n  - [Supported Tasks and Leaderboards](#supported-tasks-and-leaderboards)\n  - [Languages](#languages)\n- [Dataset Structure](#dataset-structure)\n  - [Data Instances](#data-instances)\n  - [Data Fields](#data-fields)\n  - [Data Splits](#data-splits)\n- [Dataset Creation](#dataset-creation)\n  - [Curation Rationale](#curation-rationale)\n  - [Source Data](#source-data)\n  - [Annotations](#annotations)\n  - [Personal and Sensitive Information](#personal-and-sensitive-information)\n- [Considerations for Using the Data](#considerations-for-using-the-data)\n  - [Social Impact of Dataset](#social-impact-of-dataset)\n  - [Discussion of Biases](#discussion-of-biases)\n  - [Other Known Limitations](#other-known-limitations)\n- [Additional Information](#additional-information)\n  - [Dataset Curators](#dataset-curators)\n  - [Licensing Information](#licensing-information)\n  - [Citation Information](#citation-information)\n  - [Contributions](#contributions)\n\n## Dataset Description\n\n- **Homepage:** [GitHub](https://github.com/zalandoresearch/fashion-mnist)\n- **Repository:** [GitHub](https://github.com/zalandoresearch/fashion-mnist)\n- **Paper:** [arXiv](https://arxiv.org/pdf/1708.07747.pdf)\n- **Leaderboard:**\n- **Point of Contact:**\n\n### Dataset Summary\n\nFashion-MNIST is a dataset of Zalando\'s article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\n### Supported Tasks and Leaderboards\n\n- `image-classification`: The goal of this task is to classify a given image of Zalando\'s article into one of 10 classes. The leaderboard is available [here](https://paperswithcode.com/sota/image-classification-on-fashion-mnist).\n\n### Languages\n\n[More Information Needed]\n\n## Dataset Structure\n\n### Data Instances\n\nA data point comprises an image and its label.\n\n```\n{\n  \'image\': <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x27601169DD8>,\n  \'label\': 9\n}\n```\n\n### Data Fields\n\n- `image`: A `PIL.Image.Image` object containing the 28x28 image. Note that when accessing the image column: `dataset[0]["image"]` the image file is automatically decoded. Decoding of a large number of image files might take a significant amount of time. Thus it is important to first query the sample index before the `"image"` column, *i.e.* `dataset[0]["image"]` should **always** be preferred over `dataset["image"][0]`.\n- `label`: an integer between 0 and 9 representing the classes with the following mapping:\n  | Label | Description |\n  | --- | --- |\n  | 0 | T-shirt/top |\n  | 1 | Trouser |\n  | 2 | Pullover |\n  | 3 | Dress |\n  | 4 | Coat |\n  | 5 | Sandal |\n  | 6 | Shirt |\n  | 7 | Sneaker |\n  | 8 | Bag |\n  | 9 | Ankle boot |\n\n### Data Splits\n\nThe data is split into training and test set. The training set contains 60,000 images and the test set 10,000 images.\n\n## Dataset Creation\n\n### Curation Rationale\n\n**From the arXiv paper:**\nThe original MNIST dataset contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. "If it doesn\'t work on MNIST, it won\'t work at all", they said. "Well, if it does work on MNIST, it may still fail on others."\n\nHere are some good reasons:\n\n- MNIST is too easy. Convolutional nets can achieve 99.7% on MNIST. Classic machine learning algorithms can also achieve 97% easily. Check out our side-by-side benchmark for Fashion-MNIST vs. MNIST, and read "Most pairs of MNIST digits can be distinguished pretty well by just one pixel."\n- MNIST is overused. In this April 2017 Twitter thread, Google Brain research scientist and deep learning expert Ian Goodfellow calls for people to move away from MNIST.\n- MNIST can not represent modern CV tasks, as noted in this April 2017 Twitter thread, deep learning expert/Keras author François Chollet.\n\n### Source Data\n\n#### Initial Data Collection and Normalization\n\n**From the arXiv paper:**\nFashion-MNIST is based on the assortment on Zalando’s website. Every fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model and in an outfit. The original picture has a light-gray background (hexadecimal color: #fdfdfd) and stored in 762 × 1000 JPEG format. For efficiently serving different frontend components, the original picture is resampled with multiple resolutions, e.g. large, medium, small, thumbnail and tiny.\n\nWe use the front look thumbnail images of 70,000 unique products to build Fashion-MNIST. Those products come from different gender groups: men, women, kids and neutral. In particular, whitecolor products are not included in the dataset as they have low contrast to the background. The thumbnails (51 × 73) are then fed into the following conversion pipeline:\n\n1. Converting the input to a PNG image.\n2. Trimming any edges that are close to the color of the corner pixels. The “closeness” is defined by the distance within 5% of the maximum possible intensity in RGB space.\n3. Resizing the longest edge of the image to 28 by subsampling the pixels, i.e. some rows and columns are skipped over.\n4. Sharpening pixels using a Gaussian operator of the radius and standard deviation of 1.0, with increasing effect near outlines.\n5. Extending the shortest edge to 28 and put the image to the center of the canvas.\n6. Negating the intensities of the image.\n7. Converting the image to 8-bit grayscale pixels.\n\n#### Who are the source language producers?\n\n**From the arXiv paper:**\nEvery fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model and in an outfit.\n\n### Annotations\n\n#### Annotation process\n\n**From the arXiv paper:**\nFor the class labels, they use the silhouette code of the product. The silhouette code is manually labeled by the in-house fashion experts and reviewed by a separate team at Zalando. Each product Zalando is the Europe’s largest online fashion platform. Each product contains only one silhouette code.\n\n#### Who are the annotators?\n\n**From the arXiv paper:**\nThe silhouette code is manually labeled by the in-house fashion experts and reviewed by a separate team at Zalando.\n\n### Personal and Sensitive Information\n\n[More Information Needed]\n\n## Considerations for Using the Data\n\n### Social Impact of Dataset\n\n[More Information Needed]\n\n### Discussion of Biases\n\n[More Information Needed]\n\n### Other Known Limitations\n\n[More Information Needed]\n\n## Additional Information\n\n### Dataset Curators\n\nHan Xiao and Kashif Rasul and Roland Vollgraf\n\n### Licensing Information\n\nMIT Licence\n\n### Citation Information\n\n```\n@article{DBLP:journals/corr/abs-1708-07747,\n  author    = {Han Xiao and\n               Kashif Rasul and\n               Roland Vollgraf},\n  title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n               Algorithms},\n  journal   = {CoRR},\n  volume    = {abs/1708.07747},\n  year      = {2017},\n  url       = {http://arxiv.org/abs/1708.07747},\n  archivePrefix = {arXiv},\n  eprint    = {1708.07747},\n  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}\n```\n\n### Contributions\n\nThanks to [@gchhablani](https://github.com/gchablani) for adding this dataset.', 'model_index': None, 'widget_data': None, 'config': None, 'transformers_info': None, 'spaces': None, 'safetensors': None, 'used_storage': None, 'extracted_code': ''}]}}, 'experiment_code': None}

## Experiment Runs

- Run ID: proposed-2-Layer-MLP-0.1M-parameters--Fashion-MNIST
  Method: proposed
  Model: 2-Layer MLP (≈0.1M parameters)
  Dataset: Fashion-MNIST

- Run ID: comparative-1-2-Layer-MLP-0.1M-parameters--Fashion-MNIST
  Method: comparative-1
  Model: 2-Layer MLP (≈0.1M parameters)
  Dataset: Fashion-MNIST


# Requirements

## Configuration Structure
Each run configuration should include:
- run_id: Unique identifier for this run
- method: The method name (baseline, proposed, ablation, etc.)
- model: Model-specific parameters (name, architecture details, hyperparameters)
- dataset: Dataset-specific parameters (name, preprocessing settings, split ratios)
- training: Training hyperparameters (learning rate, batch size, epochs, optimizer settings)
- optuna: Hyperparameter search space definition for Optuna optimization
  - Define search spaces for key hyperparameters using Optuna's suggest methods
  - Example: learning_rate: [1e-5, 1e-3], batch_size: [16, 32, 64]
- Any other experiment-specific settings

## Format
- Generate one YAML configuration per experiment run
- Ensure valid YAML syntax
- Use meaningful parameter values based on the research method and experimental design

## Example Configuration
```yaml
run_id: baseline_bert_imdb
method: baseline
model:
  name: bert-base-uncased
  hidden_size: 768
  num_layers: 12
dataset:
  name: imdb
  max_length: 512
  batch_size: 32
training:
  learning_rate: 2e-5
  epochs: 3
  optimizer: adamw
  warmup_steps: 500
optuna:
  n_trials: 20
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-5
      high: 1e-3
    batch_size:
      type: categorical
      choices: [16, 32, 64]
```

# Experimental Environment
NVIDIA A100×8
VRAM：80GB×8
RAM：2048 GB

# Instructions
1. Generate one YAML configuration for each experiment run listed above
2. Ensure configurations reflect the differences between baseline, proposed, and ablation methods
3. Use appropriate hyperparameters based on the experimental design
4. Include Optuna search space if hyperparameter optimization is beneficial for the experiment
5. For Optuna search spaces, use appropriate distribution types:
   - loguniform: For learning rates, regularization parameters
   - uniform: For dropout rates, weight decay
   - int: For hidden dimensions, number of layers
   - categorical: For discrete choices like batch size, optimizer type

Generate the configurations now:
Output:
{
  "run_configs": [
    {
      "run_id": "proposed-2-Layer-MLP-0.1M-parameters--Fashion-MNIST",
      "run_config_yaml": "run_id: proposed-2-Layer-MLP-0.1M-parameters--Fashion-MNIST\nmethod: proposed\nalgorithm:\n  name: CA-BOIL\n  n_init_points: 3         # Sobol seed evaluations\n  total_evaluations: 40    # 3 initial + 37 BO steps\n  cost_model:\n    type: gp\n    kernel: matern_plus_white\n  acquisition:\n    type: ei_over_risk_adjusted_cost\n    kappa: 1.0             # default; can be tuned by Optuna\n    formula: \"EI / (mu_c + kappa * sigma_c)\"\nmodel:\n  name: 2-layer-mlp\n  input_dim: 784           # 28×28 images flattened\n  hidden_units: 200        # placeholder, will be overridden by Optuna suggestion\n  activation: relu\n  output_dim: 10\n  parameter_budget: \"≈0.1M\"\ndataset:\n  name: fashion_mnist\n  root: ./data\n  train_size: 50000        # 83 % of full train split\n  val_size: 10000          # 17 % of full train split\n  normalization: true\ntraining:\n  epochs: 10               # fixed according to protocol\n  batch_size: 128\n  optimizer: adam\n  weight_decay: 0.0\n  max_grad_norm: 1.0\n  device: cuda\nlogging:\n  use_wandb: true\n  project: ca-boil\n  log_interval: 1          # log after each evaluation\nresources:\n  gpus_per_trial: 1\n  gpu_type: A100\n  cpus_per_trial: 4\n  memory_gb: 16\noptuna:\n  n_trials: 50\n  direction: maximize\n  sampler: tpe\n  pruner: median\n  search_space:\n    learning_rate:\n      type: loguniform\n      low: 1e-4\n      high: 1e-1\n    hidden_units:\n      type: int\n      low: 50\n      high: 400\n      step: 1\n    kappa:\n      type: uniform\n      low: 0.5\n      high: 2.0\n"
    },
    {
      "run_id": "comparative-1-2-Layer-MLP-0.1M-parameters--Fashion-MNIST",
      "run_config_yaml": "run_id: comparative-1-2-Layer-MLP-0.1M-parameters--Fashion-MNIST\nmethod: comparative-1\nalgorithm:\n  name: BOIL\n  n_init_points: 3\n  total_evaluations: 40\n  cost_model:\n    type: linear           # original BOIL uses plain LinearRegression\n  acquisition:\n    type: log_ei_minus_log_cost\n    formula: \"log(EI) - log(mu_c)\"\nmodel:\n  name: 2-layer-mlp\n  input_dim: 784\n  hidden_units: 200        # placeholder, tuned by Optuna\n  activation: relu\n  output_dim: 10\n  parameter_budget: \"≈0.1M\"\ndataset:\n  name: fashion_mnist\n  root: ./data\n  train_size: 50000\n  val_size: 10000\n  normalization: true\ntraining:\n  epochs: 10\n  batch_size: 128\n  optimizer: adam\n  weight_decay: 0.0\n  max_grad_norm: 1.0\n  device: cuda\nlogging:\n  use_wandb: true\n  project: boil-baseline\n  log_interval: 1\nresources:\n  gpus_per_trial: 1\n  gpu_type: A100\n  cpus_per_trial: 4\n  memory_gb: 16\noptuna:\n  n_trials: 50\n  direction: maximize\n  sampler: tpe\n  pruner: median\n  search_space:\n    learning_rate:\n      type: loguniform\n      low: 1e-4\n      high: 1e-1\n    hidden_units:\n      type: int\n      low: 50\n      high: 400\n      step: 1\n"
    }
  ]
}
